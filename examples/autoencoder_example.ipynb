{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and testing a 3D Vanilla Point Cloud Autoencoder\n",
    "\n",
    "## Demonstration of the implemented 3D point cloud autoencoders\n",
    "\n",
    "**LICENSE: GPL 3.0**\n",
    "This program is free software: you can redistribute it and/or modify\n",
    "it under the terms of the GNU General Public License as published by\n",
    "the Free Software Foundation, either version 3 of the License, or \n",
    "any later version.\n",
    "\n",
    "This program is distributed in the hope that it will be useful,\n",
    "but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
    "MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n",
    "GNU General Public License for more details.\n",
    "\n",
    "You should have received a copy of the GNU General Public License\n",
    "along with this program.  If not, see <https://www.gnu.org/licenses/>.\n",
    "\"\"\"\n",
    "### Related Publications\n",
    "\n",
    "T. Rios, B. van Stein, S. Menzel, T. Bäck, B. Sendhoff, P. Wollstadt,\n",
    "\"Feature Visualization for 3D Point Cloud Autoencoders\", \n",
    "International Joint Conference on Neural Networks (IJCNN), 2020\n",
    "[https://www.honda-ri.de/pubs/pdf/4354.pdf]\n",
    "\n",
    "T. Rios, T. Bäck, B. van Stein, B. Sendhoff, S. Menzel, \n",
    "\"On the Efficiency of a Point Cloud Autoencoder as a Geometric Representation\n",
    "for Shape Optimization\", 2019 IEEE Symposium Series on Computational Intelligence \n",
    "(SSCI), pp. 791-798, 2019.\n",
    "[https://www.honda-ri.de/pubs/pdf/4199.pdf]\n",
    "\n",
    "S. Saha, S. Menzel, L.L. Minku, X. Yao, B. Sendhoff and P. Wollstadt, \n",
    "\"Quantifying The Generative Capabilities Of Variational Autoencoders \n",
    "For 3D Car Point Clouds\", 2020 IEEE Symposium Series on Computational Intelligence \n",
    "(SSCI), 2020. (submitted)\n",
    "\n",
    "### Pre-requisites:\n",
    " - Python      3.6.10\n",
    " - numpy       1.19.1\n",
    " - TensorFlow  1.14.0\n",
    " - TFLearn     0.3.2\n",
    " - cudatoolkit 10.1.168\n",
    " - cuDNN       7.6.5\n",
    " - Ubuntu      18.04\n",
    " - pandas      1.1.0\n",
    " \n",
    "**Copyright (c)\n",
    "Honda Research Institute Europe GmbH**\n",
    "\n",
    "Authors: Thiago Rios <thiago.rios@honda-ri.de>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Data set generation\n",
    "Training and testing the autoencoder requires a data set of 3D point clouds. For the purposes of the example, we will generate point clouds by generating a sphere with harmonic oscillations in the surface. We start to generate the data set by importing the necessary libraries and defining the functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "## Script for handling the exit() command in the scripts\n",
    "import sys\n",
    "from io import StringIO\n",
    "from IPython import get_ipython\n",
    "\n",
    "\n",
    "class IpyExit(SystemExit):\n",
    "    def __init__(self):\n",
    "        sys.stderr = StringIO()\n",
    "\n",
    "    def __del__(self):\n",
    "        sys.stderr.close()\n",
    "        sys.stderr = sys.__stderr__  # restore from backup\n",
    "def ipy_exit():\n",
    "    raise IpyExit\n",
    "if get_ipython():    # ...run with IPython\n",
    "    exit = ipy_exit  # rebind to custom exit\n",
    "else:\n",
    "    exit = exit      # just make exit importable\n",
    "\n",
    "\n",
    "# Sphere\n",
    "def sphere(phi, theta, fphi, ftheta, x0, y0):\n",
    "    ## point cloud array\n",
    "    pc = np.zeros((theta.shape[0], 3))\n",
    "    \n",
    "    ## Sphere\n",
    "    # radius\n",
    "    R = 1 + 0.25*np.cos(ftheta*theta) + 0.25*np.cos(fphi*phi)\n",
    "    # points\n",
    "    pc[:,0] = x0 + R*np.sin(theta)*np.cos(phi)\n",
    "    pc[:,1] = y0 + R*np.sin(theta)*np.sin(phi)\n",
    "    pc[:,2] = R*np.cos(theta)    \n",
    "    return(pc)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can systematically generate point clouds mixing the three functions. For the purposes of the example, we will generate 2500 point clouds with oscillations in the surface in the range of [0, 1.0] Hz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## X-Y space\n",
    "phi,theta = np.meshgrid(np.linspace(0,2*np.pi,50), np.linspace(0,np.pi,50))\n",
    "## Sample frequencies\n",
    "# Define random seed\n",
    "np.random.seed(0)\n",
    "# Sample frequencies\n",
    "fphi = np.random.random(2500)*1*2*np.pi\n",
    "ftheta = np.random.random(2500)*1*2*np.pi\n",
    "\n",
    "## Generate point clouds\n",
    "import os\n",
    "# data set directory\n",
    "data_dir = \"./benchmark_pointclouds\"\n",
    "if not os.path.exists(data_dir): os.system(\"mkdir {}\".format(data_dir))\n",
    "# rastrigin\n",
    "for i in range(2500):\n",
    "    # evaluate data\n",
    "    pc = sphere(phi.flatten(), theta.flatten(), fphi[i], ftheta[i], 0, 0)\n",
    "    pd.DataFrame(pc).to_csv(\"{}/pc_{}.xyz\".format(data_dir, i),\\\n",
    "                            header=None, index=None, sep=\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to train the vanilla point cloud autoencoder on the generated data, we need to call the script \"pcae_training.py\" in the _include_ directory. In the terminal, the command line is\n",
    "`python [path_to_pcae_training.py] --N [pc_size] --LR [lr_size] --GPU [gpu_id] --i [data_dir_path]`. However, for running the script in the Jupyter Notebook, the command is preceeded by `%run -i`.\n",
    "\n",
    "For training the variational point cloud autoencoder, the script is the `vpcae_training.py`, which should be called with the same inputs options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i inputscripts/pcae_training.py --N 1024 --LR 128 --GPU 0 --i benchmark_pointclouds "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the model is trained, we can test the model with respect to the quality of the point cloud reconstruction. The first step is to calculate the reconstruction loss (Chamfer Distance) on a set of point clouds, wich is specified in a text file. This test is performed with the command `python evaluate_loss.py --N [point_cloud_size] --LR [latent_representation_size] --GPU [gpu_id] --i [list_with_pointclouds_path]`, and as a list of test point clouds, we will use the test set, specified in `Network_pcae_N1024_LR_10/geometries_testing.csv`. The results of the test are stored in the file `Network_pcae_N1024_LR_10/pcae_test/reconstruction_losses.dat`\n",
    "\n",
    "For the remaining scripts, **if the Variational autoencoder is used, the option --VAE True needs to be added.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i inputscripts/evaluate_loss.py --N 1024 --LR 128 --GPU -1 --i Network_pcae_N1024_LR128/geometries_testing.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second test is to generate point clouds from samples in the latent space, which are described in a text file. Since the latent space is constrained to the interval $[-1,1]^L$, where _L_ is the dimensionality of the latent space, we can generate a set of random samples and recover the point clouds. First, to illustrate how it works, we will take ten samples from the test set, calculated in the previous step, to generate point clouds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample the latent space\n",
    "file_test = np.array(pd.read_csv(\"Network_pcae_N1024_LR128/pcae_test/reconstruction_losses.dat\"))\n",
    "lr_data = file_test[0:10,1:-1]\n",
    "# Save lr data\n",
    "pd.DataFrame(lr_data).to_csv(\"lr_data.dat\", header=None, index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This evaluation is performed by calling the command `python pointcloud_generator.py --N [point_cloud_size] --LR [latent_representation_size] --GPU [gpu_id] --i [list_with_latent_variables]`. The script reconstruct the point clouds and sotre them as `.xyz` files and `.html` scatter plots in `Network_pcae_N1024_LR_128/point_cloud_generation`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i inputscripts/pointcloud_generator.py --N 1024 --LR 128 --GPU -1 --i lr_data.dat "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will take random samples from the latent space. Since the autoencoder usually does not distribute data uniformly over the latent space, some of the samples might yield noisy os collapsed point clouds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate samples\n",
    "lr_data2 = lr_data[0,:]*(np.reshape(np.linspace(1,0,10), (-1,1)))\\\n",
    "                         + lr_data[4,:]*(np.reshape(np.linspace(0,1,10), (-1,1)))\n",
    "# Save lr data\n",
    "pd.DataFrame(lr_data2).to_csv(\"lr_data2.dat\", header=None, index=None)\n",
    "%run -i inputscripts/pointcloud_generator.py --N 1024 --LR 128 --GPU -1 --i lr_data2.dat "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
